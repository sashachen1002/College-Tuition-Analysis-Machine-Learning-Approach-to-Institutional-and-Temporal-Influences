{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Before Optimization"
      ],
      "metadata": {
        "id": "Kuhsf81KiGbM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YQaXOgKMHlDM"
      },
      "outputs": [],
      "source": [
        "# import the package\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "df = pd.read_csv('Week 25 College Tuition 1966 - 2017_v3.csv')"
      ],
      "metadata": {
        "id": "34NlHbkzIoXX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data prepocessing\n",
        "# Extract the first 4 digits from the \"Year\" column\n",
        "df['Year'] = df['Year'].str[:4]\n",
        "# Change the data type of the column 'Year' to int\n",
        "df['Year'] = df['Year'].astype('int')\n",
        "# Convert 'Institution Type' into numerical using one-hot encoding\n",
        "df = pd.get_dummies(df, columns=['Institution Type'])\n",
        "print(df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2QafbbmI3m1",
        "outputId": "68b6e95d-5714-4a77-b0ef-51dfedcdf7c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Year', 'School Type', 'Total (Inflation Adjusted)',\n",
            "       'Tuition & Fees (Inflation Adjusted)', 'Room (Inflation Adjusted)',\n",
            "       'Board (Inflation Adjusted)', 'Total', 'Tuition & Fees', 'Room',\n",
            "       'Board', 'Institution Type_All Institutions',\n",
            "       'Institution Type_Private Institutions',\n",
            "       'Institution Type_Public Institutions'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data\n",
        "# Split the data into features (X) and target variable (y)\n",
        "X = df[['Institution Type_All Institutions', 'Institution Type_Private Institutions', 'Institution Type_Public Institutions', 'Year']]\n",
        "y = df['Tuition & Fees (Inflation Adjusted)']\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
      ],
      "metadata": {
        "id": "pilBDND5JdSL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "2JvTQ0XiJhY5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build, compile, and Train Neural Network model\n",
        "\n",
        "# Build the Neural Network model\n",
        "model = Sequential()\n",
        "model.add(Dense(64, activation='relu', input_shape=(X_train.shape[1],)))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1))  # Output layer with 1 neuron for regression task\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=1)"
      ],
      "metadata": {
        "id": "nPfOQVI0JjFv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f47207c0-709e-4994-a5df-7b1fb388cd6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "9/9 [==============================] - 1s 20ms/step - loss: 108201040.0000 - val_loss: 110759896.0000\n",
            "Epoch 2/50\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 108193352.0000 - val_loss: 110751128.0000\n",
            "Epoch 3/50\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 108184104.0000 - val_loss: 110740560.0000\n",
            "Epoch 4/50\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 108173536.0000 - val_loss: 110727936.0000\n",
            "Epoch 5/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 108160040.0000 - val_loss: 110712552.0000\n",
            "Epoch 6/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 108143544.0000 - val_loss: 110693248.0000\n",
            "Epoch 7/50\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 108122576.0000 - val_loss: 110669472.0000\n",
            "Epoch 8/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 108098104.0000 - val_loss: 110639416.0000\n",
            "Epoch 9/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 108066112.0000 - val_loss: 110603240.0000\n",
            "Epoch 10/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 108029136.0000 - val_loss: 110558536.0000\n",
            "Epoch 11/50\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 107982408.0000 - val_loss: 110505232.0000\n",
            "Epoch 12/50\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 107926080.0000 - val_loss: 110441288.0000\n",
            "Epoch 13/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 107861328.0000 - val_loss: 110363152.0000\n",
            "Epoch 14/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 107782440.0000 - val_loss: 110271544.0000\n",
            "Epoch 15/50\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 107687992.0000 - val_loss: 110165048.0000\n",
            "Epoch 16/50\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 107575120.0000 - val_loss: 110042528.0000\n",
            "Epoch 17/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 107450328.0000 - val_loss: 109898640.0000\n",
            "Epoch 18/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 107308888.0000 - val_loss: 109732400.0000\n",
            "Epoch 19/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 107141232.0000 - val_loss: 109546952.0000\n",
            "Epoch 20/50\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 106954272.0000 - val_loss: 109339608.0000\n",
            "Epoch 21/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 106747520.0000 - val_loss: 109106992.0000\n",
            "Epoch 22/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 106509400.0000 - val_loss: 108852584.0000\n",
            "Epoch 23/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 106264560.0000 - val_loss: 108559568.0000\n",
            "Epoch 24/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 105969952.0000 - val_loss: 108246880.0000\n",
            "Epoch 25/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 105655032.0000 - val_loss: 107904384.0000\n",
            "Epoch 26/50\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 105312064.0000 - val_loss: 107529456.0000\n",
            "Epoch 27/50\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 104943416.0000 - val_loss: 107111976.0000\n",
            "Epoch 28/50\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 104546352.0000 - val_loss: 106657032.0000\n",
            "Epoch 29/50\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 104093680.0000 - val_loss: 106183640.0000\n",
            "Epoch 30/50\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 103615224.0000 - val_loss: 105677368.0000\n",
            "Epoch 31/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 103131032.0000 - val_loss: 105117736.0000\n",
            "Epoch 32/50\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 102567248.0000 - val_loss: 104541904.0000\n",
            "Epoch 33/50\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 102002520.0000 - val_loss: 103911944.0000\n",
            "Epoch 34/50\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 101401056.0000 - val_loss: 103229672.0000\n",
            "Epoch 35/50\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 100720688.0000 - val_loss: 102532472.0000\n",
            "Epoch 36/50\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 100035944.0000 - val_loss: 101789184.0000\n",
            "Epoch 37/50\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 99304256.0000 - val_loss: 101001608.0000\n",
            "Epoch 38/50\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 98514672.0000 - val_loss: 100183872.0000\n",
            "Epoch 39/50\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 97716984.0000 - val_loss: 99306952.0000\n",
            "Epoch 40/50\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 96874584.0000 - val_loss: 98381336.0000\n",
            "Epoch 41/50\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 95962640.0000 - val_loss: 97417056.0000\n",
            "Epoch 42/50\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 95033216.0000 - val_loss: 96400600.0000\n",
            "Epoch 43/50\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 94070632.0000 - val_loss: 95323608.0000\n",
            "Epoch 44/50\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 93028256.0000 - val_loss: 94232760.0000\n",
            "Epoch 45/50\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 91958296.0000 - val_loss: 93101392.0000\n",
            "Epoch 46/50\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 90830040.0000 - val_loss: 91948152.0000\n",
            "Epoch 47/50\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 89759040.0000 - val_loss: 90695408.0000\n",
            "Epoch 48/50\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 88582744.0000 - val_loss: 89409456.0000\n",
            "Epoch 49/50\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 87319240.0000 - val_loss: 88131920.0000\n",
            "Epoch 50/50\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 86035496.0000 - val_loss: 86841104.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7fdebf4e8460>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f'Mean Squared Error: {mse}')\n",
        "rmse = mean_squared_error(y_test, y_pred, squared=False)  # Calculate RMSE\n",
        "mape = 100 * (abs(y_test.values - y_pred.flatten()) / y_test.values).mean()  # Calculate MAPE\n",
        "print(f'Root Mean Squared Error: {rmse}')\n",
        "print(f'Mean Absolute Percentage Error: {mape:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kE86KQZgIleO",
        "outputId": "e9eef94f-c1f3-4edc-9426-1858b29de3a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 3ms/step\n",
            "Mean Squared Error: 111203527.84066017\n",
            "Root Mean Squared Error: 10545.30833312427\n",
            "Mean Absolute Percentage Error: 86.08%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optimization"
      ],
      "metadata": {
        "id": "djPVilOU_rJ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load your dataset\n",
        "df3 = pd.read_csv('Week 25 College Tuition 1966 - 2017_v3.csv')"
      ],
      "metadata": {
        "id": "DmQvHK75_4ER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data prepocessing\n",
        "# Extract the first 4 digits from the \"Year\" column\n",
        "df3['Year'] = df3['Year'].str[:4]\n",
        "# Change the data type of the column 'Year' to int\n",
        "df3['Year'] = df3['Year'].astype('int')\n",
        "# Convert 'Institution Type' into numerical using one-hot encoding\n",
        "df3 = pd.get_dummies(df3, columns=['Institution Type'])\n",
        "print(df3.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VcsuqT3Q_8EU",
        "outputId": "5d8eed5e-b775-4be4-d809-685c851a357a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Year', 'School Type', 'Total (Inflation Adjusted)',\n",
            "       'Tuition & Fees (Inflation Adjusted)', 'Room (Inflation Adjusted)',\n",
            "       'Board (Inflation Adjusted)', 'Total', 'Tuition & Fees', 'Room',\n",
            "       'Board', 'Institution Type_All Institutions',\n",
            "       'Institution Type_Private Institutions',\n",
            "       'Institution Type_Public Institutions'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data\n",
        "# Split the data into features (X) and target variable (y)\n",
        "X3 = df3[['Institution Type_All Institutions', 'Institution Type_Private Institutions', 'Institution Type_Public Institutions', 'Year']]\n",
        "y3 = df3['Tuition & Fees (Inflation Adjusted)']\n",
        "# Split the data into training and testing sets\n",
        "X3_train, X3_test, y3_train, y3_test = train_test_split(X3, y3, test_size=0.25, random_state=42)"
      ],
      "metadata": {
        "id": "qQgbpDgpADnK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X3_train_scaled = scaler.fit_transform(X3_train)\n",
        "X3_test_scaled = scaler.transform(X3_test)"
      ],
      "metadata": {
        "id": "ZNQ6krp-ANEn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to create the model\n",
        "def create_model(learning_rate=0.01, neurons_layer1=64, neurons_layer2=32):\n",
        "    model3 = Sequential()\n",
        "    model3.add(Dense(neurons_layer1, activation='relu', input_shape=(X3_train.shape[1],)))\n",
        "    model3.add(Dense(neurons_layer2, activation='relu'))\n",
        "    model3.add(Dense(1))  # Output layer with 1 neuron for regression task\n",
        "    optimizer = Adam(learning_rate=learning_rate)\n",
        "    model3.compile(optimizer=optimizer, loss='mean_squared_error')\n",
        "    return model3"
      ],
      "metadata": {
        "id": "pF0QxOQyASzr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define hyperparameters to loop through\n",
        "learning_rates = [0.01, 0.001]\n",
        "neurons_layer1_values = [64, 128]\n",
        "neurons_layer2_values = [32, 64]\n",
        "epochs_values = [50, 100]\n",
        "batch_sizes = [16, 32]\n",
        "\n",
        "best_model = None\n",
        "best_mse = float('inf')\n",
        "\n",
        "# Loop through hyperparameter combinations\n",
        "for learning_rate in learning_rates:\n",
        "    for neurons_layer1 in neurons_layer1_values:\n",
        "        for neurons_layer2 in neurons_layer2_values:\n",
        "            for epochs_val in epochs_values:\n",
        "                for batch_size_val in batch_sizes:\n",
        "                    model3 = create_model(\n",
        "                        learning_rate=learning_rate,\n",
        "                        neurons_layer1=neurons_layer1,\n",
        "                        neurons_layer2=neurons_layer2\n",
        "                    )\n",
        "                    model3.fit(X3_train_scaled, y3_train, epochs=epochs_val, batch_size=batch_size_val, verbose=0)\n",
        "                    y3_pred = model3.predict(X3_test_scaled)\n",
        "                    mse3 = mean_squared_error(y3_test, y3_pred)\n",
        "                    print(f'Learning Rate: {learning_rate}, Neurons Layer 1: {neurons_layer1}, Neurons Layer 2: {neurons_layer2}, Epochs: {epochs_val}, Batch Size: {batch_size_val}, MSE: {mse3}')\n",
        "\n",
        "                    if mse3 < best_mse:\n",
        "                        best_mse = mse3\n",
        "                        best_model = model3\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4kkjFrsW_uXW",
        "outputId": "62d07d86-7d14-4957-d74f-3876b043a98c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 4ms/step\n",
            "Learning Rate: 0.01, Neurons Layer 1: 64, Neurons Layer 2: 32, Epochs: 50, Batch Size: 16, MSE: 9002146.115171552\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "Learning Rate: 0.01, Neurons Layer 1: 64, Neurons Layer 2: 32, Epochs: 50, Batch Size: 32, MSE: 9006815.59549502\n",
            "4/4 [==============================] - 0s 11ms/step\n",
            "Learning Rate: 0.01, Neurons Layer 1: 64, Neurons Layer 2: 32, Epochs: 100, Batch Size: 16, MSE: 8771671.798158662\n",
            "4/4 [==============================] - 0s 16ms/step\n",
            "Learning Rate: 0.01, Neurons Layer 1: 64, Neurons Layer 2: 32, Epochs: 100, Batch Size: 32, MSE: 8864899.573109541\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "Learning Rate: 0.01, Neurons Layer 1: 64, Neurons Layer 2: 64, Epochs: 50, Batch Size: 16, MSE: 8868148.17641209\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "Learning Rate: 0.01, Neurons Layer 1: 64, Neurons Layer 2: 64, Epochs: 50, Batch Size: 32, MSE: 8868693.370850652\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "Learning Rate: 0.01, Neurons Layer 1: 64, Neurons Layer 2: 64, Epochs: 100, Batch Size: 16, MSE: 8810218.374636145\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "Learning Rate: 0.01, Neurons Layer 1: 64, Neurons Layer 2: 64, Epochs: 100, Batch Size: 32, MSE: 8848697.554764671\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "Learning Rate: 0.01, Neurons Layer 1: 128, Neurons Layer 2: 32, Epochs: 50, Batch Size: 16, MSE: 8810559.40538383\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "Learning Rate: 0.01, Neurons Layer 1: 128, Neurons Layer 2: 32, Epochs: 50, Batch Size: 32, MSE: 9013108.789597014\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "Learning Rate: 0.01, Neurons Layer 1: 128, Neurons Layer 2: 32, Epochs: 100, Batch Size: 16, MSE: 8804065.197475404\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "Learning Rate: 0.01, Neurons Layer 1: 128, Neurons Layer 2: 32, Epochs: 100, Batch Size: 32, MSE: 8883903.824975267\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "Learning Rate: 0.01, Neurons Layer 1: 128, Neurons Layer 2: 64, Epochs: 50, Batch Size: 16, MSE: 8845668.190982468\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "Learning Rate: 0.01, Neurons Layer 1: 128, Neurons Layer 2: 64, Epochs: 50, Batch Size: 32, MSE: 8901105.39198719\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "Learning Rate: 0.01, Neurons Layer 1: 128, Neurons Layer 2: 64, Epochs: 100, Batch Size: 16, MSE: 8771179.066912938\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "Learning Rate: 0.01, Neurons Layer 1: 128, Neurons Layer 2: 64, Epochs: 100, Batch Size: 32, MSE: 8813948.27559403\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "Learning Rate: 0.001, Neurons Layer 1: 64, Neurons Layer 2: 32, Epochs: 50, Batch Size: 16, MSE: 16184992.030407783\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "Learning Rate: 0.001, Neurons Layer 1: 64, Neurons Layer 2: 32, Epochs: 50, Batch Size: 32, MSE: 94155253.2660738\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "Learning Rate: 0.001, Neurons Layer 1: 64, Neurons Layer 2: 32, Epochs: 100, Batch Size: 16, MSE: 9661478.237430615\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "Learning Rate: 0.001, Neurons Layer 1: 64, Neurons Layer 2: 32, Epochs: 100, Batch Size: 32, MSE: 12252950.04409393\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "Learning Rate: 0.001, Neurons Layer 1: 64, Neurons Layer 2: 64, Epochs: 50, Batch Size: 16, MSE: 10729836.320885299\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "Learning Rate: 0.001, Neurons Layer 1: 64, Neurons Layer 2: 64, Epochs: 50, Batch Size: 32, MSE: 55985317.05268541\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "Learning Rate: 0.001, Neurons Layer 1: 64, Neurons Layer 2: 64, Epochs: 100, Batch Size: 16, MSE: 9415178.864248255\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "Learning Rate: 0.001, Neurons Layer 1: 64, Neurons Layer 2: 64, Epochs: 100, Batch Size: 32, MSE: 10016999.679055834\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "Learning Rate: 0.001, Neurons Layer 1: 128, Neurons Layer 2: 32, Epochs: 50, Batch Size: 16, MSE: 10358122.275005145\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "Learning Rate: 0.001, Neurons Layer 1: 128, Neurons Layer 2: 32, Epochs: 50, Batch Size: 32, MSE: 68503096.29395212\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "Learning Rate: 0.001, Neurons Layer 1: 128, Neurons Layer 2: 32, Epochs: 100, Batch Size: 16, MSE: 9381746.69664841\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "Learning Rate: 0.001, Neurons Layer 1: 128, Neurons Layer 2: 32, Epochs: 100, Batch Size: 32, MSE: 10123789.946615474\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "Learning Rate: 0.001, Neurons Layer 1: 128, Neurons Layer 2: 64, Epochs: 50, Batch Size: 16, MSE: 9970228.756489746\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "Learning Rate: 0.001, Neurons Layer 1: 128, Neurons Layer 2: 64, Epochs: 50, Batch Size: 32, MSE: 31256850.306103196\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "Learning Rate: 0.001, Neurons Layer 1: 128, Neurons Layer 2: 64, Epochs: 100, Batch Size: 16, MSE: 9217777.533929568\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "Learning Rate: 0.001, Neurons Layer 1: 128, Neurons Layer 2: 64, Epochs: 100, Batch Size: 32, MSE: 9623712.850050174\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the best model on the test set\n",
        "y3_pred_best = best_model.predict(X3_test_scaled)\n",
        "mse_best = mean_squared_error(y3_test, y3_pred_best)\n",
        "print(f'Best Model Mean Squared Error: {mse_best}')\n",
        "rmse3 = mse_best ** 0.5  # Calculate RMSE\n",
        "mape3 = 100 * (abs(y3_test.values - y3_pred.flatten()) / y3_test.values).mean()  # Calculate MAPE\n",
        "print(f'Root Mean Squared Error: {rmse3}')\n",
        "print(f'Mean Absolute Percentage Error: {mape3:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZE16SPMyEbqu",
        "outputId": "6b4c2762-4091-4adb-934e-427edc44863e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 3ms/step\n",
            "Best Model Mean Squared Error: 8771179.066912938\n",
            "Root Mean Squared Error: 2961.617643605085\n",
            "Mean Absolute Percentage Error: 37.11%\n"
          ]
        }
      ]
    }
  ]
}